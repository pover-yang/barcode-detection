from pathlib import Pathimport torchfrom PIL import Imagefrom torch.utils.data import Dataset, DataLoaderfrom utils.centernet_transforms import CenterNetTransformclass CenterNetDataset(Dataset):    def __init__(self, root_dir, mode, input_size=1024, num_classes=3, filter_labels=None):        self.root_dir = Path(root_dir)        self.img_paths, self.targets = [], []        self.load_items(mode, filter_labels=filter_labels)        self.transform = CenterNetTransform(input_size=(input_size, input_size),                                            output_size=(input_size//4, input_size//4),                                            image_mean=0.4330, image_std=0.2349,                                            num_classes=num_classes)    def load_items(self, mode, filter_labels=None):        sample_file = self.root_dir / f'{mode}.txt'        data_dir = self.root_dir / 'data'        # data_dir = self.root_dir        item_lines = open(sample_file, mode='r').readlines()        for item_line in item_lines:            line_parts = item_line.strip().split('\t')            img_path = str(data_dir / line_parts[0])            target = [list(map(float, x.split(','))) for x in line_parts[1:]]            if filter_labels is not None:                target = [x for x in target if int(x[-1]) not in filter_labels]            if len(target) == 0:                continue            self.img_paths.append(img_path)            self.targets.append(target)    def __getitem__(self, idx):        image = Image.open(self.img_paths[idx]).convert("L")        target = self.targets[idx]        image, target = self.transform(image, target)        return image, target    def __len__(self):        return len(self.img_paths)def collate_fn(batch):    imgs = []    hmaps, whs, offsets, reg_masks = [], [], [], []    for img, target in batch:        imgs.append(img)        if target is not None:            hmap, wh, offset, reg_mask = target.values()            hmaps.append(hmap)            whs.append(wh)            offsets.append(offset)            reg_masks.append(reg_mask)    imgs = torch.stack(imgs, dim=0)    if len(hmaps) > 0:        targets = {'hmap': torch.stack(hmaps, dim=0),                   'wh': torch.stack(whs, dim=0),                   'offset': torch.stack(offsets, dim=0),                   'reg_mask': torch.stack(reg_masks, dim=0)}    else:        targets = None    return imgs, targetsdef get_data_loader(conf):    train_dataset = CenterNetDataset(conf.root_dir, mode='train')    val_dataset = CenterNetDataset(conf.root_dir, mode='test')    train_loader = DataLoader(train_dataset, batch_size=conf.batch_size, shuffle=True,                              num_workers=conf.num_workers, collate_fn=collate_fn,                              pin_memory=True, persistent_workers=True)    val_loader = DataLoader(val_dataset, batch_size=conf.batch_size, shuffle=False,                            num_workers=conf.num_workers, collate_fn=collate_fn,                            pin_memory=True, persistent_workers=True)    return train_loader, val_loader