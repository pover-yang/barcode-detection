from pathlib import Pathimport cv2import matplotlib.pyplot as pltimport numpy as npimport torchimport torchvision.opsimport torchvision.transforms.functional as Ffrom PIL import Imagefrom torch.utils.data import Dataset, DataLoaderclass BarcodeDataset(Dataset):    def __init__(self, root_dir, sample_file):        self.root_dir = Path(root_dir)        self.img_paths, self.targets = [], []        self.load_items(sample_file)    # 用torchvision的格式从sample_file中读取图片路径和标签(bbox+label)    def load_items(self, sample_file):        item_lines = open(sample_file, 'r').readlines()        for item_line in item_lines:            line_parts = item_line.strip().split('\t')            img_path = str(self.root_dir / line_parts[0])            instances = [x.split(',') for x in line_parts[1:]]            boxes = [tuple(map(int, map(float, x[:4]))) for x in instances]            boxes = torch.tensor(boxes, dtype=torch.float32)            labels = [int(x[4]) for x in instances]            labels = torch.tensor(labels, dtype=torch.int64)            target = {'boxes': boxes, 'labels': labels}            self.img_paths.append(img_path)            self.targets.append(target)    def __getitem__(self, idx):        img_path = self.img_paths[idx]        image = F.to_tensor(Image.open(img_path).convert("L"))        target = self.targets[idx]        return image, target    def __len__(self):        return len(self.img_paths)class BarcodeCenterNetDataset(Dataset):    def __init__(self, root_dir, mode, input_size=1024, num_classes=3, filter_labels=None):        self.root_dir = Path(root_dir)        self.img_paths, self.targets = [], []        self.load_items(mode, filter_labels=filter_labels)        self.input_size = (input_size, input_size)        self.output_size = (input_size // 4, input_size // 4)        self.num_classes = num_classes    def load_items(self, mode, filter_labels=None):        sample_file = self.root_dir / f'{mode}.txt'        data_dir = self.root_dir / 'data'        item_lines = open(sample_file, 'r').readlines()        for item_line in item_lines:            line_parts = item_line.strip().split('\t')            img_path = str(data_dir / line_parts[0])            target = [list(map(float, x.split(','))) for x in line_parts[1:]]            if filter_labels is not None:                target = [x for x in target if int(x[-1]) not in filter_labels]            if len(target) == 0:                continue            self.img_paths.append(img_path)            self.targets.append(target)    def __getitem__(self, idx):        image = Image.open(self.img_paths[idx]).convert("L")        target = self.targets[idx]        image, target = self.resize(image, target)        image = F.to_tensor(image)        hmap, wh, offset, reg_mask = self.generate_target(target)        target = {'hmap': F.to_tensor(hmap),                  'wh': F.to_tensor(wh),                  'offset': F.to_tensor(offset),                  'reg_mask': F.to_tensor(reg_mask)}        return image, target    def resize(self, image, target):        img_w, img_h = image.size        dst_w, dst_h = self.input_size        scale = min(dst_w / img_w, dst_h / img_h)        scaled_img_w, scaled_img_h = (int(img_w * scale), int(img_h * scale))        dx = (dst_w - scaled_img_w) // 2        dy = (dst_h - scaled_img_h) // 2        scaled_image = image.resize((scaled_img_w, scaled_img_h), Image.NEAREST)        dst_img = Image.new('L', self.input_size, 128)        dst_img.paste(scaled_image, (dx, dy))  # paste image to center        dst_target = []        for i in target:            i[0] = i[0] * scale + dx            i[1] = i[1] * scale + dy            i[2] = i[2] * scale + dx            i[3] = i[3] * scale + dy            i[4] = int(i[4])  # label            dst_target.append(i)        return dst_img, dst_target    def generate_target(self, target):        hmap = np.zeros((self.output_size[0], self.output_size[1], self.num_classes), dtype=np.float32)        wh = np.zeros((self.output_size[0], self.output_size[1], 2), dtype=np.float32)        offset = np.zeros((self.output_size[0], self.output_size[1], 2), dtype=np.float32)        reg_mask = np.zeros((self.output_size[0], self.output_size[1]), dtype=np.float32)        for instance in target:            cls_id = int(instance[4])            # more precise center            bbox = torch.tensor(instance[:4], dtype=torch.float32)            xmin, ymin, xmax, ymax = bbox[:4]            center = (xmin + xmax) / 2, (ymin + ymax) / 2            center = center[0] / 4, center[1] / 4            # scale to output size, less precise center            bbox = bbox / 4            xmin, ymin, xmax, ymax = bbox[:4]            center_int = int((xmin + xmax) / 2), int((ymin + ymax) / 2)            # heatmap            h, w = ymax - ymin, xmax - xmin            radius = gaussian_radius(h, w)            radius = max(0, int(radius))            draw_gaussian(hmap[:, :, cls_id], center_int, radius)            # width and height            wh[center_int[1], center_int[0]] = 1. * w, 1. * h            # local offset            offset[center_int[1], center_int[0]] = center[0] - center_int[0], center[1] - center_int[1]            # regression mask            reg_mask[center_int[1], center_int[0]] = 1        return hmap, wh, offset, reg_mask    def __len__(self):        return len(self.img_paths)def collate_fn(batch):    imgs = []    hmaps, whs, offsets, reg_masks = [], [], [], []    for img, target in batch:        imgs.append(img)        hmap, wh, offset, reg_mask = target['hmap'], target['wh'], target['offset'], target['reg_mask']        hmaps.append(hmap)        whs.append(wh)        offsets.append(offset)        reg_masks.append(reg_mask)    imgs = torch.stack(imgs, dim=0)    targets = {'hmap': torch.stack(hmaps, dim=0),               'wh': torch.stack(whs, dim=0),               'offset': torch.stack(offsets, dim=0),               'reg_mask': torch.stack(reg_masks, dim=0)}    return imgs, targetsdef get_data_loader(conf):    train_dataset = BarcodeCenterNetDataset(conf.root_dir, mode='train')    val_dataset = BarcodeCenterNetDataset(conf.root_dir, mode='test')    train_loader = DataLoader(train_dataset, batch_size=conf.batch_size, shuffle=True,                              num_workers=conf.num_workers, collate_fn=collate_fn,                              pin_memory=True, persistent_workers=True)    val_loader = DataLoader(val_dataset, batch_size=conf.batch_size, shuffle=False,                            num_workers=conf.num_workers, collate_fn=collate_fn,                            pin_memory=True, persistent_workers=True)    return train_loader, val_loaderdef draw_gaussian(heatmap, center, radius, k=1):    diameter = 2 * radius + 1  # diameter of gaussian    gaussian = gaussian2d((diameter, diameter), sigma=diameter / 6)    h, w = heatmap.shape[:2]    x, y = center    # boundary of gaussian    left, right = min(x, radius), min(w - x, radius + 1)    top, bottom = min(y, radius), min(h - y, radius + 1)    # select the region of interest    masked_heatmap = heatmap[y - top: y + bottom, x - left: x + right]    # limit the gaussian to the region of interest    # masked_gaussian = gaussian[radius - top: radius + bottom, radius - left:radius + right]    masked_gaussian = gaussian    # 将高斯分布覆盖到heatmap上，相当于不断的在heatmap基础上添加关键点的高斯，    # 即同一种类型的框会在一个heatmap某一个类别通道上面上面不断添加。    # 最终通过函数总体的for循环，相当于不断将目标画到heatmap    if min(masked_gaussian.shape) > 0 and min(masked_heatmap.shape) > 0:  # TODO debug        np.maximum(masked_heatmap, masked_gaussian * k, out=masked_heatmap)    return heatmapdef gaussian2d(shape, sigma=1):    m, n = [(ss - 1.) / 2. for ss in shape]    y, x = np.ogrid[-m:m + 1, -n:n + 1]    h = np.exp(-(x * x + y * y) / (2 * sigma * sigma))    h[h < np.finfo(h.dtype).eps * h.max()] = 0    # 限制最小的值    return hdef gaussian_radius(height, width, min_overlap=0.1):    a1 = 1    b1 = (height + width)    c1 = width * height * (1 - min_overlap) / (1 + min_overlap)    sq1 = np.sqrt(b1 ** 2 - 4 * a1 * c1)    r1 = (b1 - sq1) / (2 * a1)    a2 = 4    b2 = 2 * (height + width)    c2 = (1 - min_overlap) * width * height    sq2 = np.sqrt(b2 ** 2 - 4 * a2 * c2)    r2 = (b2 - sq2) / (2 * a2)    a3 = 4 * min_overlap    b3 = -2 * min_overlap * (height + width)    c3 = (min_overlap - 1) * width * height    sq3 = np.sqrt(b3 ** 2 - 4 * a3 * c3)    r3 = (b3 + sq3) / (2 * a3)    return min(r1, r2, r3)def vis_img_with_labels(image, target):    label_name = {        0: '1d',        1: 'qr',        2: 'dm'    }    if type(target) == dict:        label_strs = [label_name[int(x)] for x in target['labels']]        boxes = target['boxes']    else:        label_strs = [label_name[int(x[4])] for x in target]        boxes = [list(map(int, x[:4])) for x in target]        boxes = torch.tensor(boxes, dtype=torch.float32)    image = torch.asarray(image * 255, dtype=torch.uint8)    image = torchvision.utils.draw_bounding_boxes(image, boxes, labels=label_strs, colors=(255, 0, 0), width=2)    image = np.asarray(image).transpose((1, 2, 0))    return imagedef vis_img_with_heatmap(image, heatmap):    image = np.asarray(image * 255, dtype=np.uint8).transpose((1, 2, 0))    image = cv2.resize(image, (heatmap.shape[1], heatmap.shape[0]))    image = np.stack([image, image, image], axis=2)    heatmap = np.asarray(heatmap * 255, dtype=np.uint8)    # heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)    image = cv2.addWeighted(image, 0.5, heatmap, 0.5, 0)    return imagedef vis_bbox():    dataset = BarcodeDataset(r'D:\Barcode-Detection-Data', r'D:\Barcode-Detection-Data\all.txt')    # 从dataset中随机取出20张图片，画出对应的bbox和label    indices = np.random.randint(0, len(dataset), 20)    vis_imgs = [vis_img_with_labels(*dataset[i]) for i in indices]    # 画出20张图片    fig, axes = plt.subplots(4, 5, figsize=(20, 15))    for i, ax in enumerate(axes.flatten()):        ax.imshow(vis_imgs[i])        ax.axis('off')    plt.show()def vis_hmap():    dataset = BarcodeCenterNetDataset('/Users/yjunj/Data/Barcode-Detection-Data/data',                                      '/Users/yjunj/Data/Barcode-Detection-Data/all.txt',                                      input_size=1024, num_classes=3, filter_labels=[0])    indices = np.random.randint(0, len(dataset), 20)    fig, axes = plt.subplots(4, 5, figsize=(10, 8))    vis_imgs = []    for i in indices:        image, target = dataset[i]        # 画出heatmap        vis_img = vis_img_with_heatmap(image, target['hmap'])        vis_imgs.append(vis_img)    # 画出20张图片    for i, ax in enumerate(axes.flatten()):        ax.imshow(vis_imgs[i])        ax.axis('off')    plt.show()def dataloader_test():    dataset = BarcodeCenterNetDataset('/Users/yjunj/Data/Barcode-Detection-Data/data',                                      '/Users/yjunj/Data/Barcode-Detection-Data/all.txt')    dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=4, collate_fn=collate_fn)    for i, (images, targets) in enumerate(dataloader):        print(images.shape)        print(targets['hmap'].shape)        print(targets['wh'].shape)        print(targets['offset'].shape)        breakif __name__ == '__main__':    # vis_bbox()    # vis_hmap()    dataloader_test()